{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ea90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8dde0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Simulation parameters #######\n",
    "\n",
    "N = 200                                   # Number of neurons\n",
    "N2 = int(N/2)\n",
    "\n",
    "#Synaptic connections\n",
    "p =  0.3                                 # Probability of non-zero elements in the weight matrix\n",
    "gsyn = 0.5                               # Initial synaptic strength\n",
    "\n",
    "alpha = 0.25                              # Weight regularization parameter (training)\n",
    "\n",
    "#Dynamics\n",
    "dt = 0.1                                  # Time step (time scale 10 ms)\n",
    "itmax = 1000                              # Number of iterations (1000 -> 1 sec)\n",
    "sigman = 1                                # Noise standard deviation -> noise in the dynamics\n",
    "\n",
    "\n",
    "#Stimulus\n",
    "itstim = 200                              # stimulation time\n",
    "amp_current = 20                          # stimulus intensity\n",
    "amp0 = 4                                  # changed from amp0=8 to amp0=4, in order to have the same current amplitudes as in the pre-training case for both oscillations and sequences\n",
    "\n",
    "\n",
    "#TRAINING\n",
    "ftrain = 1                               # fraction of neurons to train\n",
    "nloop  = 16                              # number of loops, 0 pre-training, last: post-training.\n",
    "nloop_train = 10                         # last training loop\n",
    "\n",
    "cant_seed = 2                            # independent simulations (for generating ensemble), is changed in learning loop\n",
    "\n",
    "\n",
    "ts= 5\n",
    "b = 1 / ts\n",
    "\n",
    "iout = np.arange(0, N)  # neurons to observe outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223a95db",
   "metadata": {},
   "source": [
    "### Folder organization\n",
    "\n",
    "A separate folder `simulation_{num_simulation}` is created for each simulation, corresponding to a different resting potential value \\(V_r\\).\n",
    "\n",
    "Within each folder, the following subdirectories are generated to organize the simulation outputs:\n",
    "\n",
    "- **`simulation_{num_simulation}_currents/`** → contains the input currents (external, noise, and synaptic).  \n",
    "- **`simulation_{num_simulation}_inputs/`** → stores the total input currents received by each neuron (sum of all current components). One file per training/testing loop.\n",
    "- **`simulation_{num_simulation}_connectivity_matrix/`** → contains the synaptic weight matrices for the pre-training (nloop=0) and after training (nloop = 11) loops.\n",
    "- **`simulation_{num_simulation}_outputs/`** → stores the network output activity of each neuron. One file per training/testing loop.\n",
    "- **`simulation_{num_simulation}_nspikes/`** → contains the spike counts for each neuron. One file per training/testing loop.\n",
    "\n",
    "A parameter file named **`simulation_{num_simulation}_parameters.csv`** is also created inside each main folder, storing all relevant simulation parameters (e.g., \\(N, p, g_{syn}, dt, \\alpha, V_t, b, V_r\\)) for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77442f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### File organization functions #######\n",
    "\n",
    "def create_subfolder(parent_folder, subfolder_name):\n",
    "    path = os.path.join(parent_folder, subfolder_name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    return path\n",
    "\n",
    "def create_folders(num_simulation): \n",
    "    # Carpeta principal de la simulación\n",
    "    folder_name = f\"simulation_{num_simulation}\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    # Subcarpetas dentro de la simulation\n",
    "\n",
    "    sub_pesos = create_subfolder(folder_name, f\"simulation_{num_simulation}_connectivity_matrix\")\n",
    "    sub_currents = create_subfolder(folder_name, f\"simulation_{num_simulation}_currents\")\n",
    "    sub_inputs = create_subfolder(folder_name, f\"simulation_{num_simulation}_inputs\")\n",
    "    sub_outputs = create_subfolder(folder_name, f\"simulation_{num_simulation}_outputs\")\n",
    "    sub_nspikes = create_subfolder(folder_name, f\"simulation_{num_simulation}_nspikes\")\n",
    "\n",
    "    return folder_name, sub_pesos, sub_currents, sub_inputs, sub_outputs, sub_nspikes\n",
    "\n",
    "\n",
    "def create_parameter_file(filename_results, num_simulation, folder_name, b, vt, vrest):\n",
    " #file donde guardo los parámetros de la simulación\n",
    "    data_parametros = {\n",
    "        'N': [N],\n",
    "        'p': [p],\n",
    "        'gsyn': [gsyn],\n",
    "        'nloop': [nloop],\n",
    "        'nloop_train':[nloop_train],\n",
    "        'cant_seed': [cant_seed],\n",
    "        'dt': [dt],\n",
    "        'itmax': [itmax],\n",
    "        'itstim': [itstim],\n",
    "        'amp_current': [amp_current],\n",
    "        'amp0': [amp0],\n",
    "        'ftrain': [ftrain],\n",
    "        'alpha': [alpha],\n",
    "        'sigman': [sigman],\n",
    "        'vt': [vt],\n",
    "        'b': [b],\n",
    "        'vrest': [vrest],\n",
    "        'results_file': [filename_results],\n",
    "    }\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data_parametros)\n",
    "    filename_parametros = f'simulation_{num_simulation}_parametros.csv'\n",
    "    csv_parametros_path = os.path.join(folder_name, filename_parametros)\n",
    "    df.to_csv(csv_parametros_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac8145d",
   "metadata": {},
   "source": [
    "Generate oscillatory target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2437146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target(romega1, romega2, amp0):\n",
    "\n",
    "    target=np.zeros((N,itmax)) \n",
    "    amp=np.random.uniform(size=N)*amp0 # Oscillation amplitude sampled uniformly between 0 and amp0\n",
    "\n",
    "    phase=np.random.uniform(0,2*np.pi,size=N) # Random phase between 0 and 2pi\n",
    "\n",
    "    index = [i for i in range(N)]\n",
    "    indexs = np.random.permutation(index) \n",
    "\n",
    "    # We assign half of the neurons to frequency romega1 and the other half to romega2\n",
    "    # To replicate that, in MEC there are mainly two oscillatory frequencies: theta and gamma \n",
    "    # Gamma is roughly five times higher in frequency than theta, so we set romega1 = 1 and romega2 = 5\n",
    "\n",
    "    romega_vec = np.zeros(N)\n",
    "\n",
    "    # Assign frequencies to neurons, randomly shuffled\n",
    "    for i in range(N2):\n",
    "\n",
    "        romega_vec[indexs[i]]= romega1\n",
    "        romega_vec[indexs[i+N2]]=romega2\n",
    "\n",
    "    \n",
    "    omega=romega_vec*2*np.pi/itmax\n",
    "\n",
    "    for it in range(itmax):\n",
    "        target[:,it]=amp*np.cos(it*omega+phase) #Oscillatory target\n",
    "\n",
    "\n",
    "            \n",
    "    return target, amp, phase, omega, romega_vec, amp0\n",
    "\n",
    "\n",
    "def save_target(seed, target, phase, omega, romega_vec, amp, amp0, num_simulation, folder_name, pqif):\n",
    "    # Save target parameters  \n",
    "    data = {'Neuron': range(N), 'Phase': phase, 'Frecuency': omega, 'romega': romega_vec, 'Amplitude': amp, 'amp0': amp0}\n",
    "    df = pd.DataFrame(data)\n",
    "    file_name = f'simulation_{num_simulation}_targets_parameters.csv'\n",
    "    csv_target_path = os.path.join(folder_name, file_name)\n",
    "    df.to_csv(csv_target_path, index=False)\n",
    "\n",
    "    # Save target matrix\n",
    "    target_df = pd.DataFrame(target.T, columns=[f'Neuron_{i}' for i in range(N)])\n",
    "    file_name_target = f'simulation_{num_simulation}_targets_{pqif}_seed{seed}.csv'\n",
    "    csv_target_path = os.path.join(folder_name, file_name_target)\n",
    "    target_df.to_csv(csv_target_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_matrix_csv(matrix, file_name):\n",
    "    with open(file_name, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        for row in matrix:\n",
    "            row_list = [str(element) for element in row.flat]\n",
    "            csv_writer.writerow(row_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3903f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####### Dynamics and learning functions #######\n",
    "\n",
    "def dynamics(x_var,r_var,I_var,nqif, b):\n",
    "    dx=np.zeros(N)\n",
    "    # Noise currents\n",
    "    I_noise_lif = np.random.randn(N - nqif)*sigman \n",
    "    I_noise_qif = np.random.randn(nqif)*sigman\n",
    "    #LIF\n",
    "    dx[nqif:] = -x_var[nqif:] + I_var[nqif:] + I_noise_lif\n",
    "    #QIF\n",
    "    dx[:nqif] = 1 - np.cos(x_var[:nqif]) + I_var[:nqif]*(1 + np.cos(x_var[:nqif])) + I_noise_qif\n",
    "    dr = -b*r_var\n",
    "    return dx,dr\n",
    "\n",
    "\n",
    "def detect(x, xnew, rnew, nspike, nqif, b, vt, vrest):\n",
    "     # LIF neurons:\n",
    "     # Neurons from index nqif onward are modeled as LIF.\n",
    "     # They spike when the membrane potential crosses the threshold (vt) from below.\n",
    "     ispike_lif = np.where(x[nqif:] < vt) and np.where(xnew[nqif:] > vt)\n",
    "     ispike_lif = ispike_lif[0] + nqif\n",
    "     if (len(ispike_lif) > 0):\n",
    "         # After a spike, increase adaptation variable r by b\n",
    "         rnew[ispike_lif[:]] = rnew[ispike_lif[:]] + b\n",
    "         # Reset membrane potential to resting value\n",
    "         xnew[ispike_lif[:]] = vrest\n",
    "         # Count one more spike for each spiking neuron\n",
    "         nspike[ispike_lif[:]] = nspike[ispike_lif[:]] + 1\n",
    "\n",
    "     # QIF neurons:\n",
    "     # Neurons from index 0 to nqif-1 are modeled as QIF.\n",
    "     # The variable x represents a phase in [0, 2π).\n",
    "     # A spike is detected when the phase increases by π or more between steps,\n",
    "     # meaning the phase has advanced through the firing point.\n",
    "     dpi = np.mod(np.pi - np.mod(x, 2 * np.pi), 2 * np.pi)  # distance to π\n",
    "     ispike_qif = np.where((xnew[:nqif] - x[:nqif]) > 0) and np.where((xnew[:nqif] - x[:nqif] - dpi[:nqif]) > 0)\n",
    "     if (len(ispike_qif) > 0):\n",
    "         # After a spike, increase adaptation variable r by b\n",
    "         rnew[ispike_qif[:]] = rnew[ispike_qif[:]] + b\n",
    "         # Count one more spike for each spiking neuron\n",
    "         nspike[ispike_qif[:]] = nspike[ispike_qif[:]] + 1\n",
    "\n",
    "     return xnew, rnew, nspike\n",
    "\n",
    "\n",
    "\n",
    "def evolution(x, r, Iext, w, nqif, it, dt, iout,nspike, b, vt, vrest):\n",
    "    # Integration of the differential equations using RK2\n",
    "    II = np.squeeze(np.asarray(Iext[:, it]))  \n",
    "    v = w.dot(r.T).A1\n",
    "    dx, dr = dynamics(x, r, II + v, nqif, b)\n",
    "    xnew = x + dt * dx / 2\n",
    "    rnew = r + dt * dr / 2\n",
    "    dx, dr = dynamics(xnew, rnew, II + v, nqif, b)\n",
    "    xnew = x + dt * dx\n",
    "    rnew = r + dt * dr\n",
    "    xnew, rnew, nspike = detect(x, xnew, rnew, nspike, nqif, b, vt, vrest)\n",
    "    x, r = np.copy(xnew), np.copy(rnew)\n",
    "\n",
    "\n",
    "    return x, r, nspike, r[iout], II, v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a53ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_connectivity_matrix(N, p, gsyn):\n",
    "    # Create a random N x N connectivity matrix with sparsity p\n",
    "    # Values are drawn from a standard normal distribution\n",
    "    w = sparse.random(N, N, p, data_rvs=np.random.randn).todense()\n",
    "    \n",
    "    # Remove autapses (no neuron connects to itself)\n",
    "    np.fill_diagonal(w, 0)\n",
    "    \n",
    "    # Scale the weights by gsyn / sqrt(p * N) to normalize input magnitude\n",
    "    w *= gsyn / np.sqrt(p * N)\n",
    "    \n",
    "    # Center each row so that the average outgoing weight is zero\n",
    "    for i in range(N):\n",
    "        i0 = np.where(w[i, :])[1]  # indices of non-zero outgoing weights\n",
    "        if len(i0) > 0:\n",
    "            av0 = np.sum(w[i, i0]) / len(i0)  # compute average of existing connections\n",
    "            w[i, i0] -= av0  # subtract average to center the row\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "def initialize_neurons(N):\n",
    "    x = np.random.uniform(size=N) * 2 * np.pi\n",
    "    r = np.zeros(N)\n",
    "    nspike = np.zeros(N)\n",
    "\n",
    "    return x, r, nspike\n",
    "\n",
    "def initialize_training(N, w):\n",
    "    \n",
    "    nind=np.zeros(N).astype('int')\n",
    "    idx=[]\n",
    "    P=[]\n",
    "    for i in range(N):\n",
    "        ind=np.where(w[i,:])[1]\n",
    "        nind[i]=len(ind)\n",
    "        idx.append(ind)\n",
    "        P.append(np.identity(nind[i])/alpha)   \n",
    "    return P, idx\n",
    "\n",
    "def currents(N, itmax):\n",
    "    Iext=np.zeros((N,itmax))\n",
    "    Ibac=amp_current*(2*np.random.uniform(size=N)-1)\n",
    "    Iext[:, :itstim] = Ibac[:, None]  # Vectorized assignment\n",
    "\n",
    "    return Iext\n",
    "\n",
    "\n",
    "\n",
    "def learning(it, iloop, w, r, P, idx, target, norm_w0, csv_writer):\n",
    "    error = target[:, it:it + 1] - w @ r.reshape(N, 1)\n",
    "    w1=np.zeros(w.shape)\n",
    "\n",
    "    for i in range(N):\n",
    "        ri = r[idx[i]].reshape(len(idx[i]), 1)\n",
    "        k1 = P[i] @ ri\n",
    "        k2 = ri.T @ P[i]\n",
    "        den = 1 + ri.T @ k1\n",
    "        P[i] -= (k1 @ k2) / den\n",
    "        dw = error[i, 0] * P[i] @ r[idx[i]]\n",
    "        w[i, idx[i]] += dw\n",
    "    #     w1[i,idx[i]]+=dw   ## I commented out this part, because it takes a lot of time and can be uncommented when needed. Do same as here in sequences.\n",
    "\n",
    "\n",
    "    # if it % 10 == 0:\n",
    "    #     modt_value = (it-itstim) + (iloop-1) * (itmax-itstim)\n",
    "    #     modw_value = np.log(np.linalg.norm(w1)/norm_w0)\n",
    "\n",
    "        \n",
    "    #     # Guardar los valores en el archivo CSV\n",
    "    #     csv_writer.writerow([modt_value, modw_value])\n",
    "    return w, P\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da8ce42",
   "metadata": {},
   "source": [
    "Here we calculate the motifs. You can express them in terms of the components of the connectivity matrix.\n",
    "I think it becomes easy to understand why we calculate the motifs this way once you write them as sums of the individual matrix elements. I attach the formulas for the reciprocal and convergent motifs. I recommend that you write the other two yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f2fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# display(Image(filename=\"motif_examples.png\", width=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "888bd08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Motifs and dimensionality calculations #######\n",
    "            \n",
    "def motifs(w,gsyn,N):\n",
    "\n",
    "\n",
    "    \n",
    "    w=w-np.mean(w)\n",
    "    \n",
    "    ww=np.matmul(w,w)\n",
    "    wtw=np.matmul(w.T,w)\n",
    "    wwt=np.matmul(w,w.T)\n",
    "    \n",
    "    sigma2=np.trace(wwt)/N\n",
    "    \n",
    "    tau_rec=np.trace(ww)\n",
    "    tau_rec/=sigma2*N\n",
    "    \n",
    "    tau_div=np.sum(wwt)-np.trace(wwt)\n",
    "    tau_div/=sigma2*N*(N-1)\n",
    "    \n",
    "    tau_con=np.sum(wtw)-np.trace(wtw)\n",
    "    tau_con/=sigma2*N*(N-1)\n",
    "    \n",
    "    tau_chn=2*(np.sum(ww)-np.trace(ww))\n",
    "    tau_chn/=sigma2*N*(N-1)\n",
    "    \n",
    "    return sigma2,tau_rec,tau_div,tau_con,tau_chn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a2c2b",
   "metadata": {},
   "source": [
    "Here we calculate the dpr in terms of the diagonal and the non-diagonal components of the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e240419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# display(Image(filename=\"covariance.png\", width=500))\n",
    "# display(Image(filename=\"dahmen_dpr_b.png\", width=500)) # Mathematical suplementary of Dahmen et al. 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcb88ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpr_bias(ccorr,N,nloop):\n",
    "    a=np.extract(np.identity(N),ccorr)\n",
    "    c=np.extract(1-np.identity(N),ccorr)\n",
    "    am2=np.mean(a)**2\n",
    "    astd2=np.var(a)*N/(N-1)\n",
    "    cm2=np.mean(c)**2\n",
    "    cstd2=np.var(c)*N*(N-1)/(N*(N-1)-2)\n",
    "    \n",
    "    astd_bias2=astd2*(nloop-1)/(nloop+1) -2*(am2-cm2)/(nloop-1)+ 2*cstd2/(nloop+1)\n",
    "    cstd_bias2=(nloop-1)*cstd2/nloop - (am2-cm2)/nloop -4*(cm2-np.sqrt(am2*cm2))/(nloop*(N+1))\n",
    "    \n",
    "    dpr_bias=N/(1+(astd_bias2/am2)+(N-1)*((cstd_bias2/am2)+(cm2/am2)))\n",
    "    \n",
    "    return dpr_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f1a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Main simulation loop #######\n",
    "\n",
    "\n",
    "# Loop over different network compositions (LIF, QIF, and mixed)\n",
    "for pqif in [0, 0.25, 0.5, 0.75, 1]:  # I changed to all pqif compositions here\n",
    "    num_simulation = 0 # Initialized for creating one folder for each different vrest value\n",
    "\n",
    "    if pqif==1:\n",
    "        vt_vect = [None] # The theta model of QIF neurons has a fixed threshold at infinity\n",
    "    else:\n",
    "        vt_vect = [0]  # LIF\n",
    "\n",
    "\n",
    "    for vt in vt_vect:\n",
    "        if vt==0:\n",
    "            vrest_vect = [-8.5, -12.3, -17, -22] # Included all four vrest values, one per simulation\n",
    "        if vt == None:\n",
    "            vrest_vect = [None, None, None, None] # The theta model of QIF neurons has a fixed resting potential at  -infinity, but four elements is included in list so there is one in each simulation\n",
    "\n",
    "        \n",
    "        for vrest in vrest_vect:\n",
    "            num_simulation +=1\n",
    "            #create folders\n",
    "            nombre_carpeta, sub_pesos, sub_currents, sub_inputs, sub_outputs, sub_nspikes = create_folders(num_simulation)\n",
    "            #save target parameters and matrix\n",
    "\n",
    "            filename_results = f'simulation_{num_simulation}_results.csv'\n",
    "            create_parameter_file(filename_results, num_simulation, nombre_carpeta, b, vt, vrest=vrest)\n",
    "\n",
    "            # here we save the motif values\n",
    "            csv_file_path = os.path.join(nombre_carpeta, filename_results)\n",
    "            column_names = [ 'pqif' ,'seed','nloop', 'sigma2', 'tau_rec','tau_div','tau_con','tau_chn']\n",
    "            cant_seed = 2 #sometimes we use more seed for averaging. There are many random variables in the simulation as currents, connectivity, initial conditions.\n",
    "\n",
    "            with open(csv_file_path, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                if file.tell() == 0:\n",
    "                    writer.writerow(column_names)\n",
    "                \n",
    "\n",
    "                path_currents_seed = os.path.join(sub_currents, f'simulation_{num_simulation}_currents_pqif_{pqif}.csv')\n",
    "\n",
    "                with open(path_currents_seed, mode='a', newline='') as file_:\n",
    "                    writer_ = csv.writer(file_)\n",
    "                    if file_.tell() == 0:\n",
    "                        writer_.writerow(['pqif', 'seed', 'iloop', 'it', 'II_0', 'v_0', 'Inoise_0', 'II_1', 'v_1', 'Inoise_1', 'II_N2+1', 'v_N2+1','Inoise_N2+1', 'II_N2+2', 'v_N2+2', 'Inoise_N2+2'])\n",
    "\n",
    "                    nqif = int(N * pqif)\n",
    "\n",
    "\n",
    "                    for seed in range(cant_seed):\n",
    "\n",
    "                        target, phase, amp, omega, romega_vec, amp0 = generate_target(romega1=1, romega2=5, amp0=amp0)  # moved inside seed loop\n",
    "                        \n",
    "                        save_target(seed, target, phase=phase, omega=omega, romega_vec=romega_vec, amp=amp, amp0=amp0, num_simulation=num_simulation, folder_name=nombre_carpeta, pqif=pqif)   # moved inside seed loop\n",
    "\n",
    "\n",
    "                        np.random.seed(seed = seed)\n",
    "\n",
    "                        x, r, nspike = initialize_neurons(N)\n",
    "\n",
    "                        # external current\n",
    "                        Iext= currents(N, itmax)\n",
    "\n",
    "                        path_currents_seed = os.path.join(nombre_carpeta, f'simulation_{num_simulation}_Iext_pqif_{pqif}_seed_{seed}.csv')\n",
    "                        save_matrix_csv(Iext, path_currents_seed)\n",
    "\n",
    "                        w = initialize_connectivity_matrix(N, p, gsyn)\n",
    "\n",
    "                        norm_w0 = np.linalg.norm(w)\n",
    "\n",
    "                        P, idx = initialize_training(N, w)\n",
    "\n",
    "                        filename_dw = os.path.join(nombre_carpeta, f'simulation_{num_simulation}_dw_pqif_{pqif}_seed_{seed}.csv')\n",
    "\n",
    "                        with open(filename_dw, mode='w', newline='') as file:\n",
    "                            csv_writer_dw = csv.writer(file)\n",
    "                            csv_writer_dw.writerow(['modt', 'modw'])  # Escribir encabezados\n",
    "\n",
    "                            for iloop in range(nloop):\n",
    "\n",
    "                                path_inputs= os.path.join(sub_inputs, f'simulation_{num_simulation}_inputs_pqif_{pqif}_iloop_{iloop}_seed_{seed}.csv')\n",
    "                                path_nspikes = os.path.join(sub_nspikes, f'simulation_{num_simulation}_nspikes_pqif_{pqif}_iloop_{iloop}_seed_{seed}.csv')\n",
    "                                path_outputs= os.path.join(sub_outputs, f'simulation_{num_simulation}_outputs_pqif_{pqif}_iloop_{iloop}_seed_{seed}.csv')\n",
    "\n",
    "                                for it in range(itmax):\n",
    "                                    nspike = np.zeros(N)\n",
    "\n",
    "                                    x, r, nspike, rout, II, v = evolution(x, r, Iext, w, nqif, it, dt, iout, nspike, b, vt=vt, vrest=vrest)\n",
    "\n",
    "                                    entrada = II +v\n",
    "\n",
    "                                    rout_row = rout.reshape(1, -1)\n",
    "                                    entrada_row = entrada.reshape(1,-1)\n",
    "\n",
    "\n",
    "\n",
    "                                    if iloop in [nloop_train + 1, nloop - 1] and it % 20 == 0:\n",
    "                                        writer_.writerow([pqif, seed, iloop, it, II[0], v[0], II[1], v[1], II[N2+1], v[N2+1], II[N2+2], v[N2+2]])\n",
    "\n",
    "                                    # learning, only in the training loops (0<=iloop<=nloop_train)\n",
    "                                    if  iloop>0  and iloop <= nloop_train and int(it>itstim):\n",
    "                                        w, P = learning(it, iloop, w, r, P, idx, target, norm_w0, csv_writer_dw)\n",
    "\n",
    "\n",
    "                                    nspike_row = np.array(nspike).reshape(1, -1)\n",
    "                                    \n",
    "\n",
    "                                    # Save `nspike_row` as a row in the CSV\n",
    "                                    with open(path_nspikes, 'a') as f:\n",
    "                                        np.savetxt(f, nspike_row, delimiter=',')\n",
    "\n",
    "                                    # Save `entrada_row` as a row in the CSV\n",
    "                                    with open(path_inputs, 'a') as f:\n",
    "                                        np.savetxt(f, entrada_row, delimiter=',')\n",
    "\n",
    "                                    # Save `rout_row` as a row in the CSV\n",
    "                                    with open(path_outputs, 'a') as f:\n",
    "                                        np.savetxt(f, rout_row, delimiter=',')\n",
    "\n",
    "\n",
    "                                sigma2,tau_rec,tau_div,tau_con,tau_chn=motifs(w,gsyn,N)\n",
    "                                \n",
    "\n",
    "\n",
    "                                if iloop == 0 or iloop == (nloop_train + 1):\n",
    "                                    path_w_seed = os.path.join(sub_pesos, f'simulation_{num_simulation}_pesos_pqif_{pqif}_matriz_iloop_{iloop}_semilla_{seed}')\n",
    "                                    save_matrix_csv(w, path_w_seed)\n",
    "\n",
    "\n",
    "\n",
    "                                writer.writerow([\n",
    "                                    pqif,\n",
    "                                    seed,\n",
    "                                    iloop,\n",
    "                                    sigma2,\n",
    "                                    tau_rec,\n",
    "                                    tau_div,\n",
    "                                    tau_con,\n",
    "                                    tau_chn, \n",
    "                                        \n",
    "                                \n",
    "                                ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
